{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are you mad enough to sell more clothes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.tabletmag.com/wp-content/files_mf/menken620.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is from a fairly high end clothing chain store in the North East of the US.\n",
    "\n",
    "You are a data analyst for this store. Your job is to write a report to the pointy-haired boss in which you show how you can increase the store's profit by being targeted about whom to send a catalog in the mail. Yes, you are in direct marketing. You are a quant amongst the \"mad men\". \n",
    "\n",
    "You need to explore and layout in simple terms, what the business needs to spend to increase its profit. In other words, you need a budget, and its your job to figure out how much as well.\n",
    "\n",
    "We'll guide you through the process. There is much more you can explore, of-course, but this and the subsequent lab will walk you through an entire real world classification and analysis process with a finite amount of work and computer runtime.\n",
    "\n",
    "The idea for this lab, and the attendant data set is taken from the book \"Data Mining Methods and Models\" by [Larose](http://www.dataminingconsultant.com/DMMM.htm). Henceforth we refer to this book as DMMM. There is an analysis of the data set there as well (ch7, the book is available online through our library), which you might be interested in. It is far more detailed than this homework, talking about log-normal data transformations, amongst other things.\n",
    "\n",
    "(Image credit: www.tabletmag.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This documentation of the fields is taken verbatim from DMMM).\n",
    "\n",
    "The clothing-store data set contains information about 28,799 customers in the following 51 fields:\n",
    "\n",
    "- Customer ID: unique, encrypted customer identification `HHKEY`\n",
    "- Zip code `ZIP_CODE`\n",
    "- Number of purchase visits `FRE`\n",
    "- Total net sales `MON`\n",
    "- Average amount spent per visit `AVRG`\n",
    "- Amount spent at each of four different franchises (four variables) `AMSPEND`, `PSSPEND`, `CCSPEND`, `AXSPEND`\n",
    "- Amount spent in the past month, the past three months, and the past six months `OMONSPEND`, `TMONSPEND`, `SMONSPEND`\n",
    "- Amount spent the same period last year `PREVPD`\n",
    "- Gross margin percentage `GMP`\n",
    "- Number of marketing promotions on file `PROMOS`\n",
    "- Number of days the customer has been on file `DAYS`\n",
    "- Number of days between purchases `FREDAYS`\n",
    "- Markdown percentage on customer purchases `MARKDOWN`\n",
    "- Number of different product classes purchased `CLASSES`\n",
    "- Number of coupons used by the customer `COUPONS`\n",
    "- Total number of individual items purchased by the customer `STYLES`\n",
    "- Number of stores the customer shopped at `STORES`\n",
    "- Number of promotions mailed in the past year `MAILED`\n",
    "- Number of promotions responded to in the past year `RESPONDED`\n",
    "- Promotion response rate for the past year `RESPONSERATE`\n",
    "- Product uniformity (low score = diverse spending patterns) `HI`\n",
    "- Lifetime average time between visits `LTFREDAYS`\n",
    "- Microvision lifestyle cluster type `CLUSTYPE`\n",
    "- Percent of returns `PERCRET`\n",
    "- Flag: credit card user `CC_CARD`\n",
    "- Flag: valid phone number on file `VALPHON`\n",
    "- Flag: Web shopper `WEB`\n",
    "- 15 variables providing the percentages spent by the customer on specific classes of clothing, including sweaters, knit tops, knit dresses, blouses, jackets, career pants, casual pants, shirts, dresses, suits, outerwear, jewelry, fashion, legwear, and the collectibles line; (`P*`, `PJACKETS` for example) also a variable showing the brand of choice (encrypted)\n",
    "- **Target variable**: response to promotion `RESP`...this is our **response** or **y**.\n",
    "\n",
    "\n",
    "These data are based on a direct mail marketing campaign conducted last year. We want to use this information to develop classification models for this yearâ€™s marketing campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Features and a simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get, check, clean,  the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHKEY</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>REC</th>\n",
       "      <th>FRE</th>\n",
       "      <th>MON</th>\n",
       "      <th>CC_CARD</th>\n",
       "      <th>AVRG</th>\n",
       "      <th>PC_CALC20</th>\n",
       "      <th>PSWEATERS</th>\n",
       "      <th>PKNIT_TOPS</th>\n",
       "      <th>PKNIT_DRES</th>\n",
       "      <th>PBLOUSES</th>\n",
       "      <th>PJACKETS</th>\n",
       "      <th>PCAR_PNTS</th>\n",
       "      <th>PCAS_PNTS</th>\n",
       "      <th>PSHIRTS</th>\n",
       "      <th>PDRESSES</th>\n",
       "      <th>PSUITS</th>\n",
       "      <th>POUTERWEAR</th>\n",
       "      <th>PJEWELRY</th>\n",
       "      <th>PFASHION</th>\n",
       "      <th>PLEGWEAR</th>\n",
       "      <th>PCOLLSPND</th>\n",
       "      <th>AMSPEND</th>\n",
       "      <th>PSSPEND</th>\n",
       "      <th>CCSPEND</th>\n",
       "      <th>AXSPEND</th>\n",
       "      <th>TMONSPEND</th>\n",
       "      <th>OMONSPEND</th>\n",
       "      <th>SMONSPEND</th>\n",
       "      <th>PREVPD</th>\n",
       "      <th>GMP</th>\n",
       "      <th>PROMOS</th>\n",
       "      <th>DAYS</th>\n",
       "      <th>FREDAYS</th>\n",
       "      <th>MARKDOWN</th>\n",
       "      <th>CLASSES</th>\n",
       "      <th>COUPONS</th>\n",
       "      <th>STYLES</th>\n",
       "      <th>STORES</th>\n",
       "      <th>STORELOY</th>\n",
       "      <th>VALPHON</th>\n",
       "      <th>WEB</th>\n",
       "      <th>MAILED</th>\n",
       "      <th>RESPONDED</th>\n",
       "      <th>RESPONSERATE</th>\n",
       "      <th>HI</th>\n",
       "      <th>LTFREDAY</th>\n",
       "      <th>CLUSTYPE</th>\n",
       "      <th>PERCRET</th>\n",
       "      <th>RESP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9955600066402</td>\n",
       "      <td>1001</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0</td>\n",
       "      <td>184.23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>17</td>\n",
       "      <td>666</td>\n",
       "      <td>333.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.81</td>\n",
       "      <td>111.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9955600073501</td>\n",
       "      <td>1028</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258.00</td>\n",
       "      <td>1</td>\n",
       "      <td>64.50</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>55.99</td>\n",
       "      <td>258.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>14</td>\n",
       "      <td>696</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>32.72</td>\n",
       "      <td>43.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9955600076313</td>\n",
       "      <td>1056</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10</td>\n",
       "      <td>343</td>\n",
       "      <td>171.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>68.60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9955600078045</td>\n",
       "      <td>1118</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>846.06</td>\n",
       "      <td>1</td>\n",
       "      <td>105.75</td>\n",
       "      <td>11</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>373.87</td>\n",
       "      <td>166.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24</td>\n",
       "      <td>701</td>\n",
       "      <td>87.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67</td>\n",
       "      <td>23.27</td>\n",
       "      <td>26.96</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9955600078517</td>\n",
       "      <td>1107</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.52</td>\n",
       "      <td>24.50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HHKEY  ZIP_CODE  REC  FRE     MON  CC_CARD    AVRG  PC_CALC20  PSWEATERS  PKNIT_TOPS  PKNIT_DRES  PBLOUSES  PJACKETS  PCAR_PNTS  PCAS_PNTS  PSHIRTS  PDRESSES  PSUITS  POUTERWEAR  PJEWELRY  PFASHION  PLEGWEAR  PCOLLSPND  AMSPEND  PSSPEND  CCSPEND  AXSPEND  TMONSPEND  OMONSPEND  SMONSPEND  PREVPD   GMP  PROMOS  DAYS  FREDAYS  MARKDOWN  CLASSES  COUPONS  STYLES  STORES  STORELOY VALPHON  WEB  MAILED  RESPONDED  RESPONSERATE      HI  LTFREDAY  CLUSTYPE  PERCRET  RESP\n",
       "0  9955600066402      1001  208    2  368.46        0  184.23         11       0.18        0.00        0.00      0.30       0.0       0.25       0.00     0.19      0.00     0.0         0.0  0.000000      0.02      0.03       0.29      0.0      0.0   368.46      0.0       0.00       0.00       0.00    0.00  0.60      17   666   333.00      0.08        9        1      11       1         7       N    0       5          0          0.00   31.81    111.00        10     0.00     0\n",
       "1  9955600073501      1028    6    4  258.00        1   64.50         11       0.26        0.16        0.00      0.00       0.0       0.18       0.14     0.00      0.18     0.0         0.0  0.000000      0.00      0.02       0.37      0.0      0.0   258.00      0.0     138.00      55.99     258.00    0.00  0.54      14   696   174.00      0.33        6        0      14       1         7       Y    0       4          2         50.00   32.72     43.50        10     0.03     1\n",
       "2  9955600076313      1056  327    2   77.00        0   38.50         11       1.00        0.00        0.00      0.00       0.0       0.00       0.00     0.00      0.00     0.0         0.0  0.000000      0.00      0.00       0.00      0.0      0.0    77.00      0.0       0.00       0.00       0.00   39.00  0.62      10   343   171.50      0.11        1        0       2       1         7       N    0       4          0          0.00  100.00     68.60        16     0.00     0\n",
       "3  9955600078045      1118   66    8  846.06        1  105.75         11       0.38        0.00        0.05      0.06       0.2       0.17       0.00     0.05      0.00     0.0         0.0  0.005307      0.03      0.01       0.00      0.0      0.0   846.06      0.0     104.94       0.00     373.87  166.25  0.43      24   701    87.62      0.29       15        3      35       1         7       Y    0       9          6         66.67   23.27     26.96        10     0.00     0\n",
       "4  9955600078517      1107   49    1   87.44        0   87.44         11       0.20        0.20        0.00      0.00       0.0       0.00       0.41     0.00      0.00     0.0         0.0  0.170000      0.00      0.00       0.00      0.0      0.0    87.44      0.0      87.44       0.00      87.44    0.00  0.22       0    49    49.00      0.42        4        0       8       1         7       Y    0       0          0          0.00   28.52     24.50        20     0.00     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./data/Clothing_Store.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21740, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll delete some columns we dont intend to use, and which I couldnt quite figure out what they were from the original data set and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['CLUSTYPE']\n",
    "del df['HHKEY'], df['ZIP_CODE'], df['REC'], df['PC_CALC20'] \n",
    "del df['STORELOY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FRE', 'MON', 'CC_CARD', 'AVRG', 'PSWEATERS', 'PKNIT_TOPS', 'PKNIT_DRES', 'PBLOUSES', 'PJACKETS', 'PCAR_PNTS', 'PCAS_PNTS', 'PSHIRTS', 'PDRESSES', 'PSUITS', 'POUTERWEAR', 'PJEWELRY', 'PFASHION', 'PLEGWEAR', 'PCOLLSPND', 'AMSPEND', 'PSSPEND', 'CCSPEND', 'AXSPEND', 'TMONSPEND', 'OMONSPEND', 'SMONSPEND', 'PREVPD', 'GMP', 'PROMOS', 'DAYS', 'FREDAYS', 'MARKDOWN', 'CLASSES', 'COUPONS', 'STYLES', 'STORES', 'VALPHON', 'WEB', 'MAILED', 'RESPONDED', 'RESPONSERATE', 'HI', 'LTFREDAY', 'PERCRET',\n",
       "       'RESP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy of the dataframe to make transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering is one of the most important \"human inputs\" that go into machine learning. Machines can run algorithms, but if you feed in garbage, you will get out garbage. The features that are important, or the feature combinations that might be useful in a problem, are inputs that humans can use to help the machine along. Domain knowledge is particularly useful. \n",
    "\n",
    "We first list the columns that are percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERCENT_VARS=[ u'PSWEATERS', u'PKNIT_TOPS', u'PKNIT_DRES', u'PBLOUSES', u'PJACKETS', u'PCAR_PNTS', u'PCAS_PNTS', u'PSHIRTS', \n",
    "              u'PDRESSES', u'PSUITS', u'POUTERWEAR', u'PJEWELRY', u'PFASHION', u'PLEGWEAR', u'PCOLLSPND']\n",
    "len(PERCENT_VARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look for columns where the existence or lack thereof of a zero may be important in a classifier. We used our intuition to make these choices, believing that there is additional information encoded in say, `PERCRET`: if you never returned anything you might not be a budget shopper and thus someone who might have the money to shop quite a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZERO_IMPORTANT_VARS = [u'PREVPD', u'AMSPEND', u'PSSPEND', u'CCSPEND', u'AXSPEND', u'RESPONDED', u'PERCRET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also list the columns with floating-point or integer variables that are amenable to standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STANDARDIZABLE = PERCENT_VARS + ZERO_IMPORTANT_VARS + [u'FRE', u'MON',  u'AVRG', u'GMP', u'PROMOS', u'DAYS', u'FREDAYS', u'MARKDOWN', u'CLASSES', u'COUPONS', u'STYLES',  u'MAILED',  u'RESPONSERATE', u'HI', u'LTFREDAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, an **indicator variable** is one which takes a few, usually 2 values (1/0, True/False) to code the existence or lack thereof of a property or feature. We look for existing indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_CARD [0 1]\n",
      "VALPHON ['N' 'Y']\n",
      "WEB [0 1]\n",
      "RESP [0 1]\n"
     ]
    }
   ],
   "source": [
    "for v in df.columns:\n",
    "    l=df[v].unique()\n",
    "    if len(l) <= 10:\n",
    "        print(v, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero important indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode VALPHON, PERCENT_VARS, and ZERO_IMPORTANT_VARS as indicators. By doing this we are saying: the fact that these features are non-zero carries additional importance as compared to their values.\n",
    "\n",
    "We maintain a global list INDICATORS in which the names of these columns are stored, prepending an `i_` to each of these variables to denote that they are indicators.\n",
    "\n",
    "Note that all changes are now being made to the `dftouse` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename some indicators and make them all 1-0\n",
    "dftouse['i_VALPHON']=(df.VALPHON=='Y')*1\n",
    "del dftouse['VALPHON']\n",
    "dftouse.rename(columns={'WEB':'i_WEB', 'CC_CARD':'i_CC_CARD'}, inplace=True)\n",
    "INDICATORS=['i_VALPHON','i_WEB','i_CC_CARD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the `ZERO_IMPORTANT_VARS`, the ones we thought where presence or absence was important, and create indicators from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in ZERO_IMPORTANT_VARS:\n",
    "    dftouse['i_'+p]=(df[p] > 0.0)*1\n",
    "    INDICATORS.append('i_'+p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we create indicators for each of the percent variables `PERCENT_VARS` (following Larose's ch7), in the hope that the presence or absence of buying a particular clothing style such as blouses makes a difference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in PERCENT_VARS:\n",
    "    dftouse['i_'+p]=(df[p] > 0.0)*1\n",
    "    INDICATORS.append('i_'+p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine some features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this to communicate clearly information about recentness and savings\n",
    "\n",
    "We add two more indicators corresponding to recent spending, and recent use of a savings mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create recent usage (1 month and 3 month),  sale-shopper (markdown+coupon)\n",
    "dftouse[\"i_RECENT\"]=1*((df.OMONSPEND > 0) | (df.TMONSPEND > 0))\n",
    "dftouse[\"i_SAVER\"]=1*((df.MARKDOWN > 0) | (df.COUPONS > 0))\n",
    "INDICATORS.append(\"i_RECENT\")\n",
    "INDICATORS.append(\"i_SAVER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what we now have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRE</th>\n",
       "      <th>MON</th>\n",
       "      <th>i_CC_CARD</th>\n",
       "      <th>AVRG</th>\n",
       "      <th>PSWEATERS</th>\n",
       "      <th>PKNIT_TOPS</th>\n",
       "      <th>PKNIT_DRES</th>\n",
       "      <th>PBLOUSES</th>\n",
       "      <th>PJACKETS</th>\n",
       "      <th>PCAR_PNTS</th>\n",
       "      <th>PCAS_PNTS</th>\n",
       "      <th>PSHIRTS</th>\n",
       "      <th>PDRESSES</th>\n",
       "      <th>PSUITS</th>\n",
       "      <th>POUTERWEAR</th>\n",
       "      <th>PJEWELRY</th>\n",
       "      <th>PFASHION</th>\n",
       "      <th>PLEGWEAR</th>\n",
       "      <th>PCOLLSPND</th>\n",
       "      <th>AMSPEND</th>\n",
       "      <th>PSSPEND</th>\n",
       "      <th>CCSPEND</th>\n",
       "      <th>AXSPEND</th>\n",
       "      <th>TMONSPEND</th>\n",
       "      <th>OMONSPEND</th>\n",
       "      <th>SMONSPEND</th>\n",
       "      <th>PREVPD</th>\n",
       "      <th>GMP</th>\n",
       "      <th>PROMOS</th>\n",
       "      <th>DAYS</th>\n",
       "      <th>FREDAYS</th>\n",
       "      <th>MARKDOWN</th>\n",
       "      <th>CLASSES</th>\n",
       "      <th>COUPONS</th>\n",
       "      <th>STYLES</th>\n",
       "      <th>STORES</th>\n",
       "      <th>i_WEB</th>\n",
       "      <th>MAILED</th>\n",
       "      <th>RESPONDED</th>\n",
       "      <th>RESPONSERATE</th>\n",
       "      <th>HI</th>\n",
       "      <th>LTFREDAY</th>\n",
       "      <th>PERCRET</th>\n",
       "      <th>RESP</th>\n",
       "      <th>i_VALPHON</th>\n",
       "      <th>i_PREVPD</th>\n",
       "      <th>i_AMSPEND</th>\n",
       "      <th>i_PSSPEND</th>\n",
       "      <th>i_CCSPEND</th>\n",
       "      <th>i_AXSPEND</th>\n",
       "      <th>i_RESPONDED</th>\n",
       "      <th>i_PERCRET</th>\n",
       "      <th>i_PSWEATERS</th>\n",
       "      <th>i_PKNIT_TOPS</th>\n",
       "      <th>i_PKNIT_DRES</th>\n",
       "      <th>i_PBLOUSES</th>\n",
       "      <th>i_PJACKETS</th>\n",
       "      <th>i_PCAR_PNTS</th>\n",
       "      <th>i_PCAS_PNTS</th>\n",
       "      <th>i_PSHIRTS</th>\n",
       "      <th>i_PDRESSES</th>\n",
       "      <th>i_PSUITS</th>\n",
       "      <th>i_POUTERWEAR</th>\n",
       "      <th>i_PJEWELRY</th>\n",
       "      <th>i_PFASHION</th>\n",
       "      <th>i_PLEGWEAR</th>\n",
       "      <th>i_PCOLLSPND</th>\n",
       "      <th>i_RECENT</th>\n",
       "      <th>i_SAVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0</td>\n",
       "      <td>184.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>17</td>\n",
       "      <td>666</td>\n",
       "      <td>333.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.81</td>\n",
       "      <td>111.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>258.00</td>\n",
       "      <td>1</td>\n",
       "      <td>64.50</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>55.99</td>\n",
       "      <td>258.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>14</td>\n",
       "      <td>696</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>32.72</td>\n",
       "      <td>43.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10</td>\n",
       "      <td>343</td>\n",
       "      <td>171.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>68.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>846.06</td>\n",
       "      <td>1</td>\n",
       "      <td>105.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>373.87</td>\n",
       "      <td>166.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>24</td>\n",
       "      <td>701</td>\n",
       "      <td>87.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67</td>\n",
       "      <td>23.27</td>\n",
       "      <td>26.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.52</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FRE     MON  i_CC_CARD    AVRG  PSWEATERS  PKNIT_TOPS  PKNIT_DRES  PBLOUSES  PJACKETS  PCAR_PNTS  PCAS_PNTS  PSHIRTS  PDRESSES  PSUITS  POUTERWEAR  PJEWELRY  PFASHION  PLEGWEAR  PCOLLSPND  AMSPEND  PSSPEND  CCSPEND  AXSPEND  TMONSPEND  OMONSPEND  SMONSPEND  PREVPD   GMP  PROMOS  DAYS  FREDAYS  MARKDOWN  CLASSES  COUPONS  STYLES  STORES  i_WEB  MAILED  RESPONDED  RESPONSERATE      HI  LTFREDAY  PERCRET  RESP  i_VALPHON  i_PREVPD  i_AMSPEND  i_PSSPEND  i_CCSPEND  i_AXSPEND  i_RESPONDED  \\\n",
       "0    2  368.46          0  184.23       0.18        0.00        0.00      0.30       0.0       0.25       0.00     0.19      0.00     0.0         0.0  0.000000      0.02      0.03       0.29      0.0      0.0   368.46      0.0       0.00       0.00       0.00    0.00  0.60      17   666   333.00      0.08        9        1      11       1      0       5          0          0.00   31.81    111.00     0.00     0          0         0          0          0          1          0            0   \n",
       "1    4  258.00          1   64.50       0.26        0.16        0.00      0.00       0.0       0.18       0.14     0.00      0.18     0.0         0.0  0.000000      0.00      0.02       0.37      0.0      0.0   258.00      0.0     138.00      55.99     258.00    0.00  0.54      14   696   174.00      0.33        6        0      14       1      0       4          2         50.00   32.72     43.50     0.03     1          1         0          0          0          1          0            1   \n",
       "2    2   77.00          0   38.50       1.00        0.00        0.00      0.00       0.0       0.00       0.00     0.00      0.00     0.0         0.0  0.000000      0.00      0.00       0.00      0.0      0.0    77.00      0.0       0.00       0.00       0.00   39.00  0.62      10   343   171.50      0.11        1        0       2       1      0       4          0          0.00  100.00     68.60     0.00     0          0         1          0          0          1          0            0   \n",
       "3    8  846.06          1  105.75       0.38        0.00        0.05      0.06       0.2       0.17       0.00     0.05      0.00     0.0         0.0  0.005307      0.03      0.01       0.00      0.0      0.0   846.06      0.0     104.94       0.00     373.87  166.25  0.43      24   701    87.62      0.29       15        3      35       1      0       9          6         66.67   23.27     26.96     0.00     0          1         1          0          0          1          0            1   \n",
       "4    1   87.44          0   87.44       0.20        0.20        0.00      0.00       0.0       0.00       0.41     0.00      0.00     0.0         0.0  0.170000      0.00      0.00       0.00      0.0      0.0    87.44      0.0      87.44       0.00      87.44    0.00  0.22       0    49    49.00      0.42        4        0       8       1      0       0          0          0.00   28.52     24.50     0.00     0          1         0          0          0          1          0            0   \n",
       "\n",
       "   i_PERCRET  i_PSWEATERS  i_PKNIT_TOPS  i_PKNIT_DRES  i_PBLOUSES  i_PJACKETS  i_PCAR_PNTS  i_PCAS_PNTS  i_PSHIRTS  i_PDRESSES  i_PSUITS  i_POUTERWEAR  i_PJEWELRY  i_PFASHION  i_PLEGWEAR  i_PCOLLSPND  i_RECENT  i_SAVER  \n",
       "0          0            1             0             0           1           0            1            0          1           0         0             0           0           1           1            1         0        1  \n",
       "1          1            1             1             0           0           0            1            1          0           1         0             0           0           0           1            1         1        1  \n",
       "2          0            1             0             0           0           0            0            0          0           0         0             0           0           0           0            0         0        1  \n",
       "3          0            1             0             1           1           1            1            0          1           0         0             0           1           1           1            0         1        1  \n",
       "4          0            1             1             0           0           0            0            1          0           0         0             0           1           0           0            0         1        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21740, 69)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftouse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we've currently expanded the number of features we have in an attempt to pit in information in the form of indicators which communicate additional distinguishing (in our opinion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test and Training Sets, and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize test and training sets separately. Specifically, we wish to standardize the non-indicator columns on both the test and training sets, by subtracting out the mean of the training set from the value, and dividing by the standard deviation of the training set. This helps us put all the continuous variables on the same scale.\n",
    "\n",
    "(There is another reason this might be useful. One optimization which we dont do in this homework but which is useful is to take the log of all positive continuous variables. This makes data look more \"normal\" which can be useful in some algorithms, and then such standardization can basically be thought of in units of standard deviations of the normal distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Why this might be a good idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we do this standardization on the two sets separately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: what happens to the purity of the training data if we standardize using the entire dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "If we standardize the two sets together we no longer have a completely separate dataset to test our methods on. In this case it may not make much of a difference but itâ€™s still important to keep things separate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the dataset and create a training and test mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(range(dftouse.shape[0]), train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask=np.ones(dftouse.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ...,  True, False,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21740,), 15217)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape, mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the mask to compute the training and test parts of the dataframe. Use `StandardScaler` from `sklearn.preprocessing` to \"fit\" the columns in `STANDRARDIZABLE` on the training set. Then use the resultant estimator to transform both the training and the test parts of each of the columns in the dataframe, replacing the old unstandardized values in the `STANDARDIZABLE` columns of `dftouse` by the new standardized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSWEATERS\n",
      "PKNIT_TOPS\n",
      "PKNIT_DRES\n",
      "PBLOUSES\n",
      "PJACKETS\n",
      "PCAR_PNTS\n",
      "PCAS_PNTS\n",
      "PSHIRTS\n",
      "PDRESSES\n",
      "PSUITS\n",
      "POUTERWEAR\n",
      "PJEWELRY\n",
      "PFASHION\n",
      "PLEGWEAR\n",
      "PCOLLSPND\n",
      "PREVPD\n",
      "AMSPEND\n",
      "PSSPEND\n",
      "CCSPEND\n",
      "AXSPEND\n",
      "RESPONDED\n",
      "PERCRET\n",
      "FRE\n",
      "MON\n",
      "AVRG\n",
      "GMP\n",
      "PROMOS\n",
      "DAYS\n",
      "FREDAYS\n",
      "MARKDOWN\n",
      "CLASSES\n",
      "COUPONS\n",
      "STYLES\n",
      "MAILED\n",
      "RESPONSERATE\n",
      "HI\n",
      "LTFREDAY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for col in STANDARDIZABLE:\n",
    "    print(col)\n",
    "    valstrain=df[col].values[mask]\n",
    "    valstest=df[col].values[~mask]\n",
    "    scaler=StandardScaler().fit(valstrain)\n",
    "    outtrain=scaler.transform(valstrain)\n",
    "    outtest=scaler.fit_transform(valstest)\n",
    "    out=np.empty(mask.shape[0])\n",
    "    out[mask]=outtrain\n",
    "    out[~mask]=outtest\n",
    "    dftouse[col]=out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list `lcols` of the columns we will use in our classifier. This list should not contain the response `RESP`. How many features do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "lcols=list(dftouse.columns)\n",
    "lcols.remove(u'RESP')\n",
    "print(len(lcols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing code for a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now take this data and write a classifier to predict the response, which is in the `RESP` column of `dftouse`. This response corresponds to asking the question: will a user targeted with our advertisement respond or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the code above and encapsulate it into a function, since we are going to be running many, many classifiers here in this homework. \n",
    "\n",
    "We will provide below a function `cv_optimize`, which uses a Grid Search in parameters, and a default of 5-fold cross-validation. It takes as arguments a classifier `clf`, with hyper-parameter dictionary `parameters`, training feature matrix `X`, response `y`, number of folds `n_folds`, and custom scoring function `score_func`. It performs cross-validation using `GridSearchCV` along with a grid-search of hyperparameters. It obtains the best model by the average cross-validation score (allowing for a custom cross-validation score, not just those provided by `sklearn`), and finally returns this best model. (A custom scorer can be provided in the optional `score_func` argument to `cv_optimize`. Its default value should be `None`.)\n",
    "\n",
    "This `cv_optimize` function is passed to the `do_classify` function below, so you can see how it is to be used before writing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "cv_optimize\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV (see above)\n",
    "X: a samples-features matrix in the scikit-learn style\n",
    "y: the response vectors of 1s and 0s (+ives and -ives)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "The best estimator from the GridSearchCV, after the GridSearchCV has been used to\n",
    "fit the model.\n",
    "     \n",
    "Notes\n",
    "-----\n",
    "see do_classify and the code below for an example of how this is used\n",
    "\"\"\"\n",
    "#your code here\n",
    "def cv_optimize(clf, parameters, X, y, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    print(\"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_)\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to implement a function `do_classify` which provides a general interface to any classifier. This function `do_classify` can take either a `mask` or a `reuse_split` dictionary to specify which is the training set and which is the test set in X and y. In the former case the mask is used to choose which samples to use as training samples and which ones to use as test samples. In the latter case a dictionary is used to directly provide training and test sets. This is useful when the splits already been done and we want to test multiple classifiers on the same test set to compare their performance. An example of the `reuse_split` usage will be seen further down in this notebook. \n",
    "\n",
    "We construct the features from `featurenames` columns of the dataframe `indf`, while the column name `targetname` is used with `target1val` as the value that provides a `1` or `+ive` instance. A custom scorer can be provided in the optional `score_func` argument (with default value `None`). `n_folds` is the number of cross-validation folds, set to a default value of 5.\n",
    "\n",
    "The function prints out the accuracy score on the training and test data, and also the confusion matrix associated with this classifier (more about confusion matrix in the next part of the homework). It returns the best_fit classifier, along with the training and test sets.\n",
    "\n",
    "Note that the `parameters` dictionary is use to provide a parameter dictionary in the style of `GridSearchCV`, which indeed is used through the `cv_optimize` you provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, mode=\"mask\", reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    if mode==\"mask\":\n",
    "        mask = reuse_split\n",
    "        print(\"using mask\")\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    else:\n",
    "        print(\"using reuse split\")\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print(\"############# based on standard predict ################\")\n",
    "    print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n",
    "    print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n",
    "    print(confusion_matrix(ytest, clf.predict(Xtest)))\n",
    "    print(\"########################################################\")\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement logistic regression with Lasso based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with L1 regularization, using the `do_classify` function we defined above. L1 or Lasso regularization automatically does feature selection for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return as the estimator `clflog`, and training and test sets `Xtrain`, `ytrain`, `Xtest`, and `ytest`. Let the regularization hyperparameter `C` range in powers of 10 from 0.001 to 100. Use the `reuse_split` dictionary we calculated earlier. Remember that we want to use \"L1\" or Lasso regularization: you can do this by passing `penalty=\"l1\"` to the Logistic Regression: `clf=LogisticRegression(penalty=\"l1\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21740, 69)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftouse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21740,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'C': 100} 0.853387658539791 [mean: 0.84360, std: 0.00225, params: {'C': 0.001}, mean: 0.85010, std: 0.00370, params: {'C': 0.01}, mean: 0.85227, std: 0.00334, params: {'C': 0.1}, mean: 0.85293, std: 0.00321, params: {'C': 1}, mean: 0.85319, std: 0.00331, params: {'C': 10}, mean: 0.85339, std: 0.00323, params: {'C': 100}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.86\n",
      "Accuracy on test data:     0.85\n",
      "[[5299  140]\n",
      " [ 833  251]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clflog,Xtrain, ytrain, Xtest, ytest  = do_classify(LogisticRegression(penalty=\"l1\"), \n",
    "                              {\"C\": [0.001, 0.01, 0.1, 1, 10, 100]}, \n",
    "                              dftouse, lcols, u'RESP', 1, reuse_split=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reuse the training and test sets you computed above later in the homework. We do this by putting them into a dictionary `reuse_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuse_split=dict(Xtrain=Xtrain, Xtest=Xtest, ytrain=ytrain, ytest=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate costs and benefits from assumptions and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data is highly asymmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First notice that our data set is very highly asymmetric, with positive `RESP`onses only making up 16-17% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole data set 0.16609935602575898\n",
      "training set 0.16606427022409148 test set 0.1661812049670397\n"
     ]
    }
   ],
   "source": [
    "print(\"whole data set\", dftouse['RESP'].mean())#Highly asymmetric\n",
    "print(\"training set\", dftouse['RESP'][mask].mean(), \"test set\", dftouse['RESP'][~mask].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that a classifier which predicts that EVERY customer is a negative has an accuracy rate of 83-84%. By this we mean that **a classifier that predicts that no customer will respond to our mailing** has an accuracy of 83-84%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the accuracy of the LR to the no-customer-responds baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your comparison, and using accuracy as a metric, does the classifier seem worthwhile pursuing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You should have found about 84% accuracy here, thatâ€™s not bad at all. In order to determine whether this is reasonable or not we should compare it to the baseline of sending to all and sending to no one. Sending to all gives us something like 17% accuracy while sending to no one gives us 83.6% accuracy. Obviously the improvement here should take other things into account (such as cost, profit, etc). But 84% is technically an improvement from using essentially no information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we havent asked the most important question. Is accuracy really the relevant metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costs and the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier above had, as one of its printed outputs, a confusion matrix. It looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5299,  140],\n",
       "       [ 833,  251]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred=clflog.predict(Xtest)\n",
    "confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix above is of this form:\n",
    "\n",
    "![hwimages](./images/confusionmatrix.png)\n",
    "\n",
    "\n",
    "**Important note**: In sklearn, to obtain the confusion matrix in the form above, always have the observed `y` first, i.e.: use as `confusion_matrix(y_true, y_pred)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, +ives (those with a 1 `RESP`onse) are people who respond to the mailing by going into the store and buying goods. These are also called observed positives (OP). And -ives (those with a 0 `RESP`onse) are those who do not respond to the mailing. These are also called observed Negatives. On our test set, we can print the observed positives and observed negatives respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP= 1084 , ON= 5439\n"
     ]
    }
   ],
   "source": [
    "print(\"OP=\", ytest.sum(), \", ON=\",ytest.shape[0] - ytest.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a similar calculation on the predictions of our SVM classifier made on the test set. This gives us the predicted negatives (PN): those customers who we predict will not respond to our mailing; and the predicted positives (PP), the customers who we predict will respond to our mailing by coming into the store to buy stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP= 391 , PN= 6132\n"
     ]
    }
   ],
   "source": [
    "print(\"PP=\", ypred.sum(), \", PN=\",ytest.shape[0] - ypred.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these four quantities, the confusion matrix gives us more details on proper classifications and mis-classifications from our classifier:\n",
    "\n",
    "- the samples that are +ive and the classifier predicts as +ive are called True Positives (TP). These are folks we correctly identified as responders,and thus sending them a mailing would result in a sale for us. True Positives are great. We do incur the cost of mailing them, but we like to because they will come into the store to buy.\n",
    "- the samples that are -ive and the classifier predicts (wrongly) as +ive are called False Positives (FP). False Positives incur us the cost of mailing them as well, but are not very costly. These are people who wouldnt have responded, but we sent them a mailing because our classifier mispredicted them as buyers. Thus, for them, we only incur the cost of preparing the mailing and mailing it to them.\n",
    "- the samples that are -ive and the classifier predicts as -ive are called True Negatives (TN). These are folks we correctly identified as not-responding, and thus we dont waste any money on sending them a mailing. This is a great classification for us.\n",
    "- the samples that are +ive and the classifier predicts as -ive are called False Negatives (FN). False negatives are VERY costly: these are folks who would have responded to us had we mailed them, but we didnt target them, leading to huge lost sales per person. Notice that our SVM classifier has tons of False Negatives\n",
    "\n",
    "It is not enough to simply identify these categories from the confusion matrix. Rather, we want to sit down with our business team and identify the costs associated with each of the 4 classification situations above. Keep in mind that these costs might even change from year to year or even more suddenly: this is why it is important to have marketing and sales people on your data science teams. (See Patil, D. J. Building data science teams. \" O'Reilly Media, Inc.\", 2011.\n",
    " for more details).\n",
    " \n",
    " Fortunately you have talked to your domain experts and done just that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Costs for True Positives, False Negatives, False Positives, and True Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets categorize the costs for each one of these alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume the amortized cost of preparing a mailing and mailing it is \\$3. Lets assume additionally that the profit margin on a sale is 30% (we are a high end clothing chain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negatives cost us nothing but gain us nothing either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tnc=0.0 #tnr stands for \"true negative cost\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the average cost of a sale, and the 30% profit assumption, we calculate `tpc`, the cost of a true positive. Note: `tpc` must be negative, since we are talking about costs.\n",
    "\n",
    "The `tpc` takes into account the cost of mailing to the respondent, and since our mailing works, we subtract out the profit. We use the average of the `AVRG` column, which is the average money spent by a customer on each visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-31.166731600736753"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_and_mail=3\n",
    "profit_margin=0.3\n",
    "tpc=prep_and_mail - df.AVRG.mean()*profit_margin \n",
    "tpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The false negative is a lost sale for us! We didnt mail them, and they didnt spend the money. They would have if we mailed them. So we lost a certain profit per such false negative! Thus the false-negative cost, given by `fnc`, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.16673160073675"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnc = df.AVRG.mean()*profit_margin\n",
    "fnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with False positives. This is a person who would not have responded but you wasted $3 on. So the false positive cost, (`fpc`) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpc=prep_and_mail\n",
    "fpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost  and Utility Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use these costs to write a **risk or cost matrix** in the same form as the confusion matrix above. \n",
    "\n",
    "![cost matrix](images/costmatrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.       ,   3.       ],\n",
       "       [ 34.1667316, -31.1667316]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_matrix=np.array([[tnc, fpc],[fnc, tpc]])\n",
    "risk_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the cost of a false positive is 11 times less than the cost of a false negative. As is often the case in situations in which one class dominates the other, the costs of one kind of misclassification: false negatives are differently expensive than false positives. We saw above that FN are more costly in our case than FP. Similar situations arise in cancer prediction, for example, where a FP only means that you diagnosed a healthy person with cancer, but a FN means that you misdiagnosed a cancer patient as healthy: possibly killing them in the process!\n",
    "\n",
    "The negative of the cost matrix is called the **utility matrix or profit matrix** `u`. Here we calculate this utility matrix, which we shall use in the next part of the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.       ,  -3.       ],\n",
       "       [-34.1667316,  31.1667316]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = - risk_matrix\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Now we can use this profit matrix to calculate the profit that the SVM classifier can land us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Profit Per Person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the average profit per person using the following formula, which calculates the \"expected value\" of the per-customer profit (the $P$ below stands for \"predicted\" and $O$ for observed):\n",
    "\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "Profit &=& u(+P,+O) \\times p(+P,+O) \\\\\n",
    "       &+& u(+P,-O) \\times p(+P,-O) \\\\\n",
    "       &+& u(-P,+O) \\times p(-P,+O) \\\\\n",
    "       &+& u(-P,-O) \\times p(-P,-O) \n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "which gives\n",
    "\n",
    "\n",
    "$$ Profit =  \\frac{( TP \\times -TPC )+ ( FP \\times -FPC ) + ( FN \\times -FNC ) + ( TN \\times -TNC )}{N}$$\n",
    "\n",
    "where N is the total size of the test set, +P means predicted positive, -O is observed negative, and so on and so forth. The formula above just weighs the profit of a combination of observed and predicted with the out-of-sample probability of the combination occurring. The probabilities are \"estimated\" by the corresponding confusion matrix on the **test set**, which leads to the second formula. $-TPC$ is just the 'true positive' utility (similar for the others...).\n",
    "\n",
    "The profit can thus be found by multiplying the utility matrix by the confusion matrix elementwise, and dividing by the sum of the elements in the confusion matrix, or the test set size.\n",
    "\n",
    "We implement this process of finding the average profit per person in the `average_profit_pp` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_profit_pp(y, ypred, u):\n",
    "    c=confusion_matrix(y,ypred)\n",
    "    score=np.sum(c*u)/np.sum(c)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we make this calculation for our LR classifier, we need to first check what profit or cost our baseline classifier which assumes that no customer will respond, incurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing Baseline Classifiers via profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest classifiers you can think of are the \"send to everyone\" and \"dont send to everyone\" classifiers. We explain these below. If we are going to write any more complex classifiers we should at-least outperform these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dont Send to Anyone Baseline Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"majority\" classifier we talked about earlier. We dont send mailings to anyone because we believe that **no-one will respond**. Thus this classifier predicts everyone to be a 0 or -ive, a non-respondent. Remember, this classifier has a 83-84% accuracy.\n",
    "\n",
    "We write a confusion matrix `dste` for the \"dont send to everyone\" model (not the best acronym, I know!), and calculate the average profit per person as `dsteval`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5439    0]\n",
      " [1084    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.677868627195867"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsize = dftouse[~mask].shape[0]\n",
    "ypred_dste = np.zeros(testsize, dtype=\"int\")\n",
    "print(confusion_matrix(ytest, ypred_dste))\n",
    "dsteval=average_profit_pp(ytest, ypred_dste, u)\n",
    "dsteval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Not sending out the mailers amounts to losing $5.60 in potential profit per every person. Even sending them out randomly (untargeted) should increase potential profit. However a more targeted approach is prefered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Send to Everyone Baseline Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the other extreme. In this case we **predict everyone as responders** and send the mailing to everyone. In other words, we predict everyone on the test set to be a 1. Print out both the confusion matrix and `steval`, the average profit per person, for this case. Based on this result, which one of these two classifiers is the one to beat? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 5439]\n",
      " [   0 1084]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.677868627195867"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "ypred_ste = np.ones(testsize, dtype=\"int\")\n",
    "print(confusion_matrix(ytest, ypred_ste))\n",
    "steval = average_profit_pp(ytest, ypred_ste, u)\n",
    "steval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sending to everyone is definitely the one to beat, even when taking into account the cost of sending out to everyone weâ€™ll be making a profit of about $2.59 per person. Reading this together with question in 2.1 gives us the overall message that just one metric can not be used to effectively make an effective business decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the LR classifier with these baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.22827499488407"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "average_profit_pp(ytest, ypred, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did this correctly, at this point you might be a bit dejected, and worried about that presentation you have to make to your boss in a few days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Re-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We asked how the accuracy of our LR classifier compares to that of the baseline classifiers we tested. However, is this the real question of importance? Our dataset is a very lopsided data set with 84% of samples being negative. In such a case, accuracy is not a very good measure of a classifier.\n",
    "\n",
    "But then we see that the performance of our LR classifier, even with the \"profit\" metric instead of the accuracy metric is no big shakes. Indeed, it is outperformed by one of our baseline classifiers.\n",
    "What gives?\n",
    "\n",
    "We were doing something wrong there.\n",
    "\n",
    "In the case of such asymmetric costs, the `sklearn` API function `predict` is useless, as it assumes a threshold probability of having a +ive sample to be 0.5; that is, if a sample has a greater than 0.5 chance of being a 1, assume it is so. Clearly, when FN are more expensive than FP, you want to lower this threshold: you are ok with falsely classifying -ive examples as +ive. See Lab 5 for how this can be done.\n",
    "\n",
    "You can think about this very starkly from the perspective of the cancer doctor. Do you really want to be setting a threshold of 0.5 probability to predict if a patient has cancer or not? The false negative problem: ie the chance you predict someone dosent have cancer who has cancer is much higher for such a threshold. You could kill someone by telling them not to get a biopsy. Why not play it safe and assume a much lower threshold: for eg, if the probability of 1(cancer) is greater than 0.05, we'll call it a 1.\n",
    "\n",
    "Let us do this for our logistic regression example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with an arbitrary threshold t, and see how we fare at different thresholds for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_repredict(est,t, xtest):\n",
    "    probs=est.predict_proba(xtest)\n",
    "    p0 = probs[:,0]\n",
    "    p1 = probs[:,1]\n",
    "    ypred = (p1 > t)*1\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see average profits for multiple thresholds for the logistic regression classifier `clflog`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Average profit per person for t=0.5 (the usual case)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.22827499488407"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_profit_pp(ytest,clflog.predict(Xtest), u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Confusion Matrix and average profit per person for t=0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2437, 3002],\n",
       "       [  50, 1034]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest,t_repredict(clflog, 0.05, Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2978788740035205"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_profit_pp(ytest, t_repredict(clflog, 0.05, Xtest), u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) average profit per person for t=0.95**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.588185786660337"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_profit_pp(ytest, t_repredict(clflog, 0.95, Xtest), u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, at a 0.05 threshold we have a nice positive profit! (if you did this right...)\n",
    "\n",
    "We see that in this situation, where we have asymmetric costs (1:15), we do need to change the threshold at which we make our positive and negative predictions. We need to change the threshold so that we much dislike false nefatives (same in the cancer case). Thus we must accept many more false positives by setting such a low threshold.\n",
    "\n",
    "For otherwise, we let too many people slip through our hands who would have otherwise shopped at our store. Once we change the threshold, we can make a profit. And indeed, at $t=0.05$, our profit is higher than in the \"Send to Everyone\" case, which makes doing the classifier worth it! But how do we pick this threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso, for example, implements internally, a form of feature selection by setting many coefficients to zero. Let us find coefficients that are non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non zero lasso features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function `nonzero_lasso` which takes the fit classifier `clfloglasso` as an argument, and spits out a dataframe of coefficients, sorted by the absolute magnitude of the coefficients. This way we can see which features dominated the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nonzero_lasso(clf):\n",
    "    featuremask=(clf.coef_ !=0.0)[0]\n",
    "    return pd.DataFrame(dict(feature=lcols, coef=clf.coef_[0], abscoef=np.abs(clf.coef_[0])))[featuremask].sort_values('abscoef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abscoef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LTFREDAY</th>\n",
       "      <td>-3.447440</td>\n",
       "      <td>3.447440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_CCSPEND</th>\n",
       "      <td>-1.513719</td>\n",
       "      <td>1.513719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREDAYS</th>\n",
       "      <td>0.479357</td>\n",
       "      <td>0.479357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_WEB</th>\n",
       "      <td>0.466501</td>\n",
       "      <td>0.466501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRE</th>\n",
       "      <td>0.416635</td>\n",
       "      <td>0.416635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS</th>\n",
       "      <td>0.270157</td>\n",
       "      <td>0.270157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_AXSPEND</th>\n",
       "      <td>0.250255</td>\n",
       "      <td>0.250255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_PSSPEND</th>\n",
       "      <td>-0.229486</td>\n",
       "      <td>0.229486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_PJEWELRY</th>\n",
       "      <td>-0.126535</td>\n",
       "      <td>0.126535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_PDRESSES</th>\n",
       "      <td>0.119055</td>\n",
       "      <td>0.119055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef   abscoef\n",
       "feature                       \n",
       "LTFREDAY   -3.447440  3.447440\n",
       "i_CCSPEND  -1.513719  1.513719\n",
       "FREDAYS     0.479357  0.479357\n",
       "i_WEB       0.466501  0.466501\n",
       "FRE         0.416635  0.416635\n",
       "DAYS        0.270157  0.270157\n",
       "i_AXSPEND   0.250255  0.250255\n",
       "i_PSSPEND  -0.229486  0.229486\n",
       "i_PJEWELRY -0.126535  0.126535\n",
       "i_PDRESSES  0.119055  0.119055"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_importances=nonzero_lasso(clflog)\n",
    "lasso_importances.set_index(\"feature\", inplace=True)\n",
    "lasso_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance using correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a notion of which features are important in the classification process by seeing how they correlate with the response. Implement some code to obtain the Pearson correlation coefficient between each of our features and the response. Do this on the training set only! Create a dataframe indexed by the features, which has columns `abscorr` the absolute value of the correlation and `corr` the value of the correlation. Sort the dataframe by `abscorr`, highest first, and show the top 25 features with the highest absolute correlation. Is there much overlap with the feature selection performed by the LASSO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3l/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abscorr</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FRE</th>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSES</th>\n",
       "      <td>0.373672</td>\n",
       "      <td>0.373672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STYLES</th>\n",
       "      <td>0.357726</td>\n",
       "      <td>0.357726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONDED</th>\n",
       "      <td>0.351397</td>\n",
       "      <td>0.351397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONSERATE</th>\n",
       "      <td>0.330317</td>\n",
       "      <td>0.330317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>0.317142</td>\n",
       "      <td>0.317142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STORES</th>\n",
       "      <td>0.310259</td>\n",
       "      <td>0.310259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTFREDAY</th>\n",
       "      <td>0.308847</td>\n",
       "      <td>-0.308847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUPONS</th>\n",
       "      <td>0.308529</td>\n",
       "      <td>0.308529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMONSPEND</th>\n",
       "      <td>0.307876</td>\n",
       "      <td>0.307876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMONSPEND</th>\n",
       "      <td>0.269302</td>\n",
       "      <td>0.269302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_RESPONDED</th>\n",
       "      <td>0.258607</td>\n",
       "      <td>0.258607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_PERCRET</th>\n",
       "      <td>0.252763</td>\n",
       "      <td>0.252763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_CC_CARD</th>\n",
       "      <td>0.235376</td>\n",
       "      <td>0.235376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_RECENT</th>\n",
       "      <td>0.234917</td>\n",
       "      <td>0.234917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREDAYS</th>\n",
       "      <td>0.231753</td>\n",
       "      <td>-0.231753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI</th>\n",
       "      <td>0.230582</td>\n",
       "      <td>-0.230582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCSPEND</th>\n",
       "      <td>0.225453</td>\n",
       "      <td>0.225453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROMOS</th>\n",
       "      <td>0.223242</td>\n",
       "      <td>0.223242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAILED</th>\n",
       "      <td>0.208125</td>\n",
       "      <td>0.208125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSSPEND</th>\n",
       "      <td>0.206921</td>\n",
       "      <td>0.206921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMONSPEND</th>\n",
       "      <td>0.201132</td>\n",
       "      <td>0.201132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_PKNIT_TOPS</th>\n",
       "      <td>0.197296</td>\n",
       "      <td>0.197296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_PFASHION</th>\n",
       "      <td>0.192796</td>\n",
       "      <td>0.192796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS</th>\n",
       "      <td>0.184610</td>\n",
       "      <td>0.184610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               abscorr      corr\n",
       "feature                         \n",
       "FRE           0.412698  0.412698\n",
       "CLASSES       0.373672  0.373672\n",
       "STYLES        0.357726  0.357726\n",
       "RESPONDED     0.351397  0.351397\n",
       "RESPONSERATE  0.330317  0.330317\n",
       "MON           0.317142  0.317142\n",
       "STORES        0.310259  0.310259\n",
       "LTFREDAY      0.308847 -0.308847\n",
       "COUPONS       0.308529  0.308529\n",
       "SMONSPEND     0.307876  0.307876\n",
       "TMONSPEND     0.269302  0.269302\n",
       "i_RESPONDED   0.258607  0.258607\n",
       "i_PERCRET     0.252763  0.252763\n",
       "i_CC_CARD     0.235376  0.235376\n",
       "i_RECENT      0.234917  0.234917\n",
       "FREDAYS       0.231753 -0.231753\n",
       "HI            0.230582 -0.230582\n",
       "CCSPEND       0.225453  0.225453\n",
       "PROMOS        0.223242  0.223242\n",
       "MAILED        0.208125  0.208125\n",
       "PSSPEND       0.206921  0.206921\n",
       "OMONSPEND     0.201132  0.201132\n",
       "i_PKNIT_TOPS  0.197296  0.197296\n",
       "i_PFASHION    0.192796  0.192796\n",
       "DAYS          0.184610  0.184610"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "correlations=[]\n",
    "dftousetrain=dftouse[mask]\n",
    "for col in lcols:\n",
    "    r=pearsonr(dftousetrain[col], dftousetrain['RESP'])[0]\n",
    "    correlations.append(dict(feature=col,corr=r, abscorr=np.abs(r)))\n",
    "\n",
    "bpdf=pd.DataFrame(correlations).sort_values('abscorr', ascending=False)\n",
    "bpdf.set_index(['feature'], inplace=True)\n",
    "bpdf.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "There is some overlap between the features selected with LASSO and the highest correlations but the orders donâ€™t necessarily line up. Lifetime average time between visits, and number of purchase visits and days between purchases are some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Feature Select?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the reasons feature selection is done, automatically or otherwise, is that there might be strong correlations between features. Also recall polynomial regression: a large number of features can lead to overfitting. Feature selection helps curb the problem of the curse of dimensionality, where centrality measures often used in statistics go wonky at higher dimensions. Between feature-engineering which we did some of, earlier, and feature selection, is where a lot of smarts and domain knowledge comes in. You will gain this with experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline to feature-select, standardize and train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall use sklearn pipelines to do correlation-with-response based feature selection for our LR model. Maybe such feature-selection will improve the abysmal performance. \n",
    "\n",
    "\n",
    "Its very important to do response based feature selection in the right way. If you remember, we separately standardized the training and test sets. This was to prevent **any** information about the overall mean and standard deviation leaking into the test set. \n",
    "\n",
    "But we played a bit loose with the rules there. We standardized on the entire training set. Instead we should have been standardizing separately in each cross-validation fold. There the original training set would be broken up into a sub-training and validation set, the standardization needed to be done on those separately. This can be implemented with `sklearn` pipelines.\n",
    "\n",
    "Such kind of \"data snooping\" is relatively benign though, as it used no information about the response variable. But if you do any feature selection which uses the response variable, such as choosing the \"k\" most correlated variables from above, its not benign any more. This is because you have leaked the response from the validation into your sub-training set, and cannot thus be confident about your predictions: you might overfit. In such a situation, you must do the feature selection inside the cross-validation fold. See http://nbviewer.ipython.org/github/cs109/content/blob/master/lec_10_cross_val.ipynb from the 2013 course for a particularly dastardly case of this, where you see that the problem is particularly exacerbated when you have many more features than samples.\n",
    "\n",
    "Lets do this here using sklearn pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a scorer which returns the absolute values of the pearson correlation between the feature and the response for each sample. The specific form of the scorer is dictated to us in the API docs for `SelectKBest`, see [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html): the first argument must be an array of scores, and the second an array of p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_scorer(X,y):\n",
    "    rs=np.zeros(X.shape[1])\n",
    "    pvals=np.zeros(X.shape[1])\n",
    "    i=0\n",
    "    for v in X.T:\n",
    "        rs[i], pvals[i]=pearsonr(v, y)\n",
    "        i=i+1\n",
    "    return np.abs(rs), pvals    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets apply the feature selection to a model which did not have any automatic feature selection and performed rather poorly before: unregularizwed logistic regression. \n",
    "\n",
    "The `Pipeline` feature of sklearn chains various parts of a machine learning algorithm together. In this case we want to chain feature-selection and training in such a way that both happen freshly for each cross-validation fold (we wont bother to standardize in each cross-validation fold separately here for brevity, although you might want to do this).\n",
    "We use the `SelectKBest` meta estimator to select the 25 most correlated/anti-correlated features. We create an instance of this meta-estimator, `selectorlr`. We then combine it with the linear SVC estimators into the pipeline `pipelr`: the `Pipeline` function simply takes a list of `scikit-learn` estimators and wraps them together into a new estimator object, which can then be passed to `GridSearchCV` via our `do_classify` function. Notice how this new estimator object can be used exactly the same way as a single classifier can be used in `scikit-learn`..this uniformity of interface is one of the nice features of `sklearn`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selectorlr = SelectKBest(k=25, score_func=pearson_scorer)\n",
    "pipelr = Pipeline([('select', selectorlr), ('lr', LogisticRegression(C=100000))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us run the pipelined classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the classifier and compare the results using the ROC curve to the previous LR result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reuse split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3l/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.85\n",
      "Accuracy on test data:     0.85\n",
      "[[5329  110]\n",
      " [ 849  235]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "pipelr, _,_,_,_  = do_classify(pipelr, None, dftouse,lcols, u'RESP',1, mode=\"reuse\", reuse_split=reuse_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features did the pipelined classifier use? We can access them so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FRE', 'MON', 'i_CC_CARD', 'PSSPEND', 'CCSPEND', 'TMONSPEND',\n",
       "       'OMONSPEND', 'SMONSPEND', 'PROMOS', 'DAYS', 'FREDAYS', 'CLASSES',\n",
       "       'COUPONS', 'STYLES', 'STORES', 'MAILED', 'RESPONDED',\n",
       "       'RESPONSERATE', 'HI', 'LTFREDAY', 'i_RESPONDED', 'i_PERCRET',\n",
       "       'i_PKNIT_TOPS', 'i_PFASHION', 'i_RECENT'], dtype='<U12')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lcols)[pipelr.get_params()['select'].get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds, Comparing Models, and the ROC Curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curves are a set of classifiers, many of them, each point corresponding to a different threshold (go read Lab 6 for more details). They are useful to compare classifiers to each other and also to baseline models.\n",
    "(In the standard scenario, where we used the  classifier accuracy, this threshold is implicitly set at 0.5, and we have only one point on the ROC curve.).\n",
    "\n",
    "The practical way to do this is to order the samples by probability of being positive, or in the case of the SVM, by the `decision_function` or distance from the separating hyperplane. Then consider the sample with the highest score or highest probability of being positive. At first, only this sample is positive. Then, we take the sample with the next highest score, and call it positive. As we go down the list, we go down a threshold in score or probability. \n",
    "\n",
    "Now, for each such situation: only 1 positive, now 2 positive,....you can imagine a different classifier with a different confusion matrix. It will have its own false positives, three positives, etc. Its actually the same original classifier, but with a different threshold each time.\n",
    "\n",
    "As we keep going down the list, decreasing the threshold, more and more samples become positive, and at first, the true positives rise faster than the false positives. Once past a certain point, false positives increase faster than true positives. Now, if you want a balanced classifier, you look at this turn-around point...the northwest corner, so to speak. But if you want a classifier which penalizes false positives and false negatives differently, the point you want is different.\n",
    "\n",
    "To make a ROC curve you plot the True Positive Rate, \n",
    "\n",
    "$$TPR=\\frac{TP}{OP}$$\n",
    "\n",
    "against the False Positive Rate,\n",
    "\n",
    "$$FPR=\\frac{FP}{ON}$$\n",
    "\n",
    "as you go through this process of going down the list of samples. ROC curves are useful because they calculate one classifier per threshold and show you where you are in TPR/FPR space without making any assumptions about the utility matrix or which threshold is appropriate.\n",
    "\n",
    "\n",
    "A rote reading of the ROC curve (go to the \"northwest\" corner) is a bad idea: you must fold in the curve with any assumptions you are making about the utilities. In our case we have both an asymmetric data set, and asymmetric risk, so the north west corner may not be the right spot. Still, on the whole, a curve with a greater AUC (area under curve), or further away from the line of randomness, will give us a rough idea of what might be a better classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def make_roc(name, clf, ytest, xtest, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:#for stuff like logistic regression\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else:#for stuff like SVM\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if skip:\n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "    )\n",
    "    if labe!=None:\n",
    "        for k in range(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the usage of this function. Play with it to see how to label things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3l/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#notice for the first plot we do not pass an axes object. Subsequent calls to\n",
    "#make_roc can use the returned axes object ax.\n",
    "with sns.hls_palette(8, l=.3, s=.8):\n",
    "    ax=make_roc(\"logistic-with-lasso\",clflog, ytest, Xtest, labe=200, skip=20)\n",
    "    make_roc(\"logistic-with-kbest\",pipelr, ytest, Xtest, labe=200, skip=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proof is always in the pudding. So far we have seen the ROC curve which implements one classifier per threshold to pick an appropriate model. But why not just plot the profit on a ROC like curve to see which classifier maximizes profit? \n",
    "\n",
    "Just like in a ROC curve, we go down the sorted (by score or probability) list of samples. We one-by-one add an additional sample to our positive samples, noting down the attendant classifier's TPR and FPR and threshold. In addition to what we do for the ROC curve, we now also note down the percentage of our list of samples predicted as positive. Remember we start from the mostest positive, where the percentage labelled as positive would be minuscule, like 0.1 or so and the threshold like a 0.99 in probability or so. As we decrease the threshold, the percentage predicted to be positive clearly increases until everything is predicted positive at a threshold of 0. What we now do is, at each such additional sample/threshold (given to us by the `roc_curve` function from `sklearn`), we calculate the expected profit per person and plot it against the percentage predicted positive by that threshold to produce a profit curve. Thus, small percentages correspond to samples most likely to be positive: a percentage of 8% means the top 8% of our samples ranked by likelihood of being positive.\n",
    "\n",
    "We provide code to plot a profit curve below, to which we must provide two critical functions:\n",
    "\n",
    "- code to calculate expected profit given the TPR and FPR from a classifier (this is different than our `average_profit_pp` above as we now want this in terms of TPR and FPR.\n",
    "- code to calculate the percentage of samples classified positive.given the TPR and FPR of a classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implemented the function `percentage(tpr, fpr, priorp, priorn)` to calculate the percentage of samples classified positive at a given tpr/fpr (ie a classifier for a given threshold).\n",
    "\n",
    "The variable `priorp` is the fraction of actual positive samples in the test set (OP), and `priorn` is the percentage of actual -ive (0) samples in the test set (ON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage(tpr, fpr, priorp, priorn):\n",
    "    perc = tpr*priorp + fpr*priorn\n",
    "    return perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us implement a function to calculate average profit per person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `av_profit(tpr, fpr, util, priorp, priorn)` to calculate average profit per person given the utility matrix, the FPR rate, the TPR rate, and class balance.\n",
    "\n",
    "You will need to look at the diagram of the confusion matrix, and the formula for profit, to derive the formula used in the function you must implement. Present your derivation below the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "av_profit\n",
    "\n",
    "Inputs\n",
    "------\n",
    "tpr: true positive rate\n",
    "fpr: false positive rate\n",
    "util: utility matrix for this problem\n",
    "priorp: the probability of observed +ives (OP) on our test set\n",
    "priorn: the probability of observed +ives (ON) on our test set\n",
    "\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "The average profit per person at this (fpr, tpr) point in this ROC space.\n",
    "     \n",
    "Notes\n",
    "-----\n",
    "see make_profit below for an example of how this is used\n",
    "\"\"\"\n",
    "#your code here\n",
    "def av_profit(tpr, fpr, util, priorp, priorn):\n",
    "    profit = priorp*(util[1][1]*tpr+util[1][0]*(1.-tpr))+priorn*(util[0][0]*(1.-fpr) +util[0][1]*fpr)\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "Profit = (TPRâˆ—priorpâˆ—âˆ’TPC)+((1âˆ’TPR)âˆ—priorpâˆ—âˆ’FNC)+(FPRâˆ—priornâˆ—âˆ’FPC)+((1âˆ’FPR)âˆ—priornâˆ—âˆ’TNC)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the definition of `percentage` and `av_profit`, we can now write code to make a profit curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_profit(name, clf, ytest, xtest, util, ax=None, threshold=False, labe=200, proba=True):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else:\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    priorp=np.mean(ytest)\n",
    "    priorn=1. - priorp\n",
    "    ben=[]\n",
    "    percs=[]\n",
    "    for i,t in enumerate(thresholds):\n",
    "        perc=percentage(tpr[i], fpr[i], priorp, priorn)\n",
    "        ev = av_profit(tpr[i], fpr[i], util, priorp, priorn)\n",
    "        ben.append(ev)\n",
    "        percs.append(perc*100)\n",
    "    ax.plot(percs, ben, '-', alpha=0.3, markersize=5, label='utlity curve for %s' % name)\n",
    "    if threshold:\n",
    "        label_kwargs = {}\n",
    "        label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "        )\n",
    "        for k in range(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (percs[k], ben[k]), **label_kwargs)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot profit curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the profit curves using the function above for the logistic regression (`clflog`) and linear svm (`clfsvm`). Keep the same labels as the ROC curves. Also annotate on the graph (use matplotlib's `ax.annotate` function) the points on the profit curve corresponding to baseline models send-to-everyone annotated as STE (from `steval`) and dont-send-to-everyone annotated as DSTE (from `dsteval`). \n",
    "\n",
    "\n",
    "Some questions:\n",
    "\n",
    "(a) why you only start making a profit at a certain percentage, and (b) what is the region on interest on the graph that you might want to communicate with the company managers in terms of maximizing your profit over the baseline (Hint: you might need to draw a horizontal line on this graph to communicate this region) (c) Which classifier makes us a greater profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#your code here\n",
    "with sns.color_palette(\"bright\"):\n",
    "    ax=make_profit(\"logistic-with-lasso\",clflog, ytest, Xtest, u, threshold=True, labe=300);\n",
    "    ax.annotate(\"DSTE\", (0.0, dsteval))\n",
    "    ax.annotate(\"STE\", (100.0, steval))\n",
    "    plt.plot([0,100],[steval,steval],'k-', alpha=0.5, lw=2)\n",
    "    plt.xlim([0,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- a. The unbalanced dataset leads to profit at somewhere around 20% of people predicted positives since you need at least that many to start offsetting the losses of the many negatives. \n",
    "- b. We want to focus on the methods that give us at least the STE profit, above about 2.3. Using methods that show profits above that line will give us more profit than sending to all without sending to all. \n",
    "- c. Logistic regression with Lasso works best. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
